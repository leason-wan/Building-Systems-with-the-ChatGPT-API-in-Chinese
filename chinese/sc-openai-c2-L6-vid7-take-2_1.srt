1
00:00:01,000 --> 00:00:05,000
在本视频中，我们将重点关注系统生成的输出的检查。

2
00:00:05,000 --> 00:00:15,000
在向用户展示输出之前检查它们可能非常重要，以确保提供给他们或用于自动化流程的响应的质量、相关性和安全性。

3
00:00:15,000 --> 00:00:24,000
我们将学习如何使用审查 API，但这次是针对输出，并学习如何使用附加提示来评估输出质量，然后再显示它们。

4
00:00:24,000 --> 00:00:31,000
那么让我们深入到例子中。

5
00:00:31,000 --> 00:00:35,000
我们已经在评估输入的上下文中讨论了审查 API。

6
00:00:35,000 --> 00:00:39,000
现在让我们在检查输出的上下文中重新审视它。

7
00:00:39,000 --> 00:00:45,000
审查 API 也可以用于过滤和审查系统自动生成的输出。

8
00:00:45,000 --> 00:00:47,000
这里是一个例子。

9
00:00:47,000 --> 00:00:54,000
这是一个生成的用户响应。

10
00:00:54,000 --> 00:01:02,000
我们将使用与之前视频中相同的方式来使用审查 API。

11
00:01:02,000 --> 00:01:06,000
让我们看看这个输出是否被标记。

12
00:01:06,000 --> 00:01:16,000
正如您所看到的，这个输出没有被标记，并且在所有类别中得分非常低，这是合理的，考虑到响应。

13
00:01:16,000 --> 00:01:19,000
总的来说，检查输出也非常重要。

14
00:01:19,000 --> 00:01:28,000
例如，如果您正在为敏感受众创建聊天机器人，您可以使用更低的阈值来标记输出。

15
00:01:28,000 --> 00:01:40,000
总的来说，如果审查输出表明内容已被标记，您可以采取适当的措施，例如回复一个备用答案或生成一个新的响应。

16
00:01:40,000 --> 00:01:48,000
请注意，随着我们改进模型，它们也越来越不太可能返回某种有害输出。
 
17
00:01:48,000 --> 00:01:56,000
另一种检查输出的方法是询问模型本身是否满意生成的输出，并且是否遵循您定义的某些标准。

18
00:01:56,000 --> 00:02:05,000
这可以通过将生成的输出作为模型输入的一部分，并要求其评估输出的质量来完成。

19
00:02:05,000 --> 00:02:07,000
您可以以各种不同的方式做到这一点。

20
00:02:07,000 --> 00:02:10,000
那么让我们看一个例子。

21
00:02:10,000 --> 00:02:25,000
因此，我们的系统消息是您是一个助手，评估客户服务代理的响应是否足够回答客户问题，并验证助手从产品信息中引用的所有事实是否正确。

22
00:02:25,000 --> 00:02:33,000
产品信息和用户和客户服务代理消息将通过三个反引号传递。

23
00:02:33,000 --> 00:02:37,000
回答一个没有标点符号的Y或N字符。

24
00:02:37,000 --> 00:02:45,000
如果输出足够回答问题并且响应正确使用产品信息，则为Y，否则为N。

25
00:02:45,000 --> 00:02:47,000
我只会放一个字母。

26
00:02:47,000 --> 00:02:52,000
您还可以为此使用一种思维链推理提示。

27
00:02:52,000 --> 00:02:55,000
这可能对模型来说有点困难，因为需要在一步中验证两者。

28
00:02:55,000 --> 00:02:57,000
因此，您可以尝试一下。

29
00:02:57,000 --> 00:02:59,000
您还可以添加其他类型的指南。

30
00:02:59,000 --> 00:03:05,000
您可以询问是否使用了友好的语气，符合我们的品牌指南的规定，并可能概述您的品牌指南，如果这对您非常重要。

31
00:03:05,000 --> 00:03:15,000
您可以使用这种格式，例如考试的评分标准或论文的评分标准。

32
00:03:15,000 --> 00:03:17,000
因此，让我们添加我们的客户消息。
 
33
00:03:17,000 --> 00:03:21,000
这是用于生成此响应的初始消息。

34
00:03:21,000 --> 00:03:24,000
然后将其粘贴到我们的产品信息中。

35
00:03:24,000 --> 00:03:33,000
因此，这是我们在前一步中获取的所有提到的产品的产品信息。

36
00:03:33,000 --> 00:03:37,000
现在我们将定义我们的比较。

37
00:03:37,000 --> 00:03:51,000
因此，客户消息是客户消息，产品信息以及代理响应，即我们从此前的单元格中获得的对客户的响应。

38
00:03:51,000 --> 00:03:59,000
因此，让我们将其格式化为消息列表并从模型中获取响应。

39
00:03:59,000 --> 00:04:06,000
因此，模型表示，是的，产品信息是正确的，并且问题得到了充分回答。

40
00:04:06,000 --> 00:04:15,000
总的来说，对于这些类型的评估任务，我认为最好使用更高级的模型，因为它们更擅长推理。

41
00:04:15,000 --> 00:04:20,000
所以像GPT-4这样的东西。

42
00:04:20,000 --> 00:04:23,000
让我们再试一个例子。

43
00:04:23,000 --> 00:04:27,000
因此，这个响应是生命就像一盒巧克力。

44
00:04:27,000 --> 00:04:36,000
因此，让我们添加与输出检查相关的消息。

45
00:04:36,000 --> 00:04:43,000
模型已确定这不能充分回答问题或使用检索到的信息。

46
00:04:43,000 --> 00:04:46,000
这个问题，它是否正确使用了检索到的信息？

47
00:04:46,000 --> 00:04:59,000
如果您想确保模型没有产生幻觉（即编造不真实的事物），这是一个很好的提示。

48
00:04:59,000 --> 00:05:11,000
请随意暂停视频，尝试一些自己的客户消息、响应和添加产品信息，以测试它的工作原理。
 
49
00:05:11,000 --> 00:05:21,000
正如您所看到的，该模型可以提供有关生成输出质量的反馈，您可以使用此反馈来决定是否向用户呈现输出或生成新的响应。

50
00:05:21,000 --> 00:05:28,000
您甚至可以尝试为每个用户查询生成多个模型响应，然后让模型选择最佳响应以向用户显示。

51
00:05:28,000 --> 00:05:30,000
因此，您可以尝试许多不同的事情。

52
00:05:30,000 --> 00:05:44,000
总的来说，使用审核 API 检查输出是一个好的实践，但是要求模型评估自己的输出可能对于确保非常少量情况下响应质量的即时反馈是有用的。

53
00:05:44,000 --> 00:05:50,000
我认为大多数情况下这可能是不必要的，特别是如果您正在使用像 GPT-4 这样更先进的模型。

54
00:05:50,000 --> 00:05:54,000
实际上，我没有看到很多人在生产中做这样的事情。

55
00:05:54,000 --> 00:06:01,000
您还可以增加系统的延迟和成本，因为您必须等待模型的额外调用，这也是额外的令牌。

56
00:06:01,000 --> 00:06:10,000
如果您的应用程序或产品的错误率非常重要为 0.0000001%，那么也许您应该尝试这种方法。

57
00:06:10,000 --> 00:06:13,000
但总的来说，我不会真正建议您在实践中这样做。

58
00:06:13,000 --> 00:06:22,000
在下一个视频中，我们将把我们在评估输入部分、处理部分和检查输出部分学到的所有内容组合起来，构建一个端到端的系统。

59
00:06:22,000 --> 00:06:24,000
谢谢。