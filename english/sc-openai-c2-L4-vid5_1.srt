1
00:00:00,000 --> 00:00:10,080
In this section, we'll focus on tasks to process inputs, i.e. the tasks that take the input

2
00:00:10,080 --> 00:00:13,880
and generate a useful output, often through a series of steps.

3
00:00:13,880 --> 00:00:17,980
It is sometimes important for the model to reason in detail about a problem before answering

4
00:00:17,980 --> 00:00:23,160
a specific question, and if you took our previous course, ChartGBT Prompt Engineering for Developers,

5
00:00:23,160 --> 00:00:26,040
you will have seen a number of examples of this.

6
00:00:26,040 --> 00:00:30,280
Sometimes a model might make reasoning errors by rushing to an incorrect conclusion, so

7
00:00:30,280 --> 00:00:35,160
we can reframe the query to request a series of relevant reasoning steps before the model

8
00:00:35,160 --> 00:00:40,640
provides a final answer, so that it can think longer and more methodically about the problem.

9
00:00:40,640 --> 00:00:45,280
In general, we call this strategy of asking the model to reason about a problem in steps,

10
00:00:45,280 --> 00:00:46,880
chain of thought reasoning.

11
00:00:46,880 --> 00:00:51,600
For some applications, the reasoning process that a model uses to arrive at a final answer

12
00:00:51,600 --> 00:00:54,000
would be inappropriate to share with the user.

13
00:00:54,000 --> 00:00:58,480
For example, in tutoring applications, we may want to encourage students to work on

14
00:00:58,480 --> 00:01:02,400
their own answers, but a model's reasoning process about the student's solution could

15
00:01:02,400 --> 00:01:04,920
reveal the answer to the student.

16
00:01:04,920 --> 00:01:09,120
Inner monologue is a tactic that can be used to mitigate this, and this is just a fancy

17
00:01:09,120 --> 00:01:13,600
way of saying, hiding the model's reasoning from the user.

18
00:01:13,600 --> 00:01:17,280
The idea of inner monologue is to instruct the model to put parts of the output that

19
00:01:17,280 --> 00:01:21,280
are meant to be hidden from the user into a structured format that makes passing them

20
00:01:21,280 --> 00:01:22,280
easy.

21
00:01:22,280 --> 00:01:26,360
Then, before presenting the output to the user, the output is passed and only part of

22
00:01:26,360 --> 00:01:29,080
the output is made visible.

23
00:01:29,080 --> 00:01:32,880
So remember the classification problem from a previous video, where we asked the model

24
00:01:32,880 --> 00:01:37,840
to classify a customer query into a primary and secondary category.

25
00:01:37,840 --> 00:01:42,040
And based on that classification, we might want to take different instructions.

26
00:01:42,040 --> 00:01:46,860
Imagine the customer query had been classified into the product information category.

27
00:01:46,860 --> 00:01:51,600
In the next instructions, we'll want to include information about the products we have available.

28
00:01:51,600 --> 00:01:57,640
And so, in this case, the classification would have been primary, general inquiry, secondary,

29
00:01:57,640 --> 00:01:58,640
product information.

30
00:01:58,640 --> 00:02:02,360
And so let's dive into an example starting from there.

31
00:02:02,360 --> 00:02:08,760
So let's start with our usual setup.

32
00:02:08,760 --> 00:02:15,800
So for this inner monologue example, we'll start with our same delimiters that we've

33
00:02:15,800 --> 00:02:16,800
been using.

34
00:02:16,800 --> 00:02:22,960
And now let's go through our system message.

35
00:02:22,960 --> 00:02:27,680
And so what we're doing here is asking the model to reason about the answer before coming

36
00:02:27,680 --> 00:02:30,400
to its conclusion.

37
00:02:30,400 --> 00:02:34,540
So the instruction is, follow these steps to answer the customer queries.

38
00:02:34,540 --> 00:02:39,280
The customer query will be delimited with four hashtags, our delimiter.

39
00:02:39,280 --> 00:02:42,080
So then we've split this up into steps.

40
00:02:42,080 --> 00:02:46,880
So the first step is to decide whether the user is asking a question about a specific

41
00:02:46,880 --> 00:02:47,880
product or products.

42
00:02:47,880 --> 00:02:50,920
And a product category doesn't count.

43
00:02:50,920 --> 00:02:55,920
Step two, so if the user is asking about specific products, identify whether the products are

44
00:02:55,920 --> 00:02:57,480
in the following list.

45
00:02:57,480 --> 00:03:00,440
And now we've included a list of available products.

46
00:03:00,440 --> 00:03:02,680
So here we have five available products.

47
00:03:02,680 --> 00:03:05,800
They're all varieties of laptops.

48
00:03:05,800 --> 00:03:09,560
And these are all made up products.

49
00:03:09,560 --> 00:03:14,000
They were actually generated by GPT-4.

50
00:03:14,000 --> 00:03:20,480
In step three, if the message contains products in the list above, list any assumptions that

51
00:03:20,480 --> 00:03:22,480
the user is making in their message.

52
00:03:22,480 --> 00:03:29,720
For example, that laptop X is bigger than laptop Y or that laptop Z has a two-year warranty,

53
00:03:29,720 --> 00:03:33,360
for example.

54
00:03:33,360 --> 00:03:37,840
Step four is if the user made any assumptions, figure out whether the assumption is true

55
00:03:37,840 --> 00:03:39,840
based on your product information.

56
00:03:39,840 --> 00:03:45,920
And step five is first, politely correct the customer's incorrect assumptions, if applicable.

57
00:03:45,920 --> 00:03:49,440
Only mention or reference products in the list of five available products, as these

58
00:03:49,440 --> 00:03:51,840
are the only five products that the store sells.

59
00:03:51,840 --> 00:03:54,480
And answer the customer in a friendly tone.

60
00:03:54,480 --> 00:03:59,160
And these kind of very pedantic instructions are probably unnecessary for a more advanced

61
00:03:59,160 --> 00:04:01,840
language model like GPT-4.

62
00:04:01,840 --> 00:04:05,440
And then we'll ask the model to use the following format.

63
00:04:05,440 --> 00:04:08,920
So step one, delimiter, it's reasoning.

64
00:04:08,920 --> 00:04:12,080
Step two, delimiter, reasoning, and so on.

65
00:04:12,080 --> 00:04:16,600
And using the delimiters will mean that it will be easier for us later to get just this

66
00:04:16,600 --> 00:04:23,120
response to the customer and kind of cut off everything before.

67
00:04:23,120 --> 00:04:27,240
So now let's try an example user message.

68
00:04:27,240 --> 00:04:33,560
So our message is, by how much is the BlueWave Chromebook more expensive than the TechPro

69
00:04:33,560 --> 00:04:34,880
desktop?

70
00:04:34,880 --> 00:04:39,280
So let's take a look at these two products.

71
00:04:39,280 --> 00:04:48,440
The BlueWave Chromebook is $249.99, and the TechPro desktop is actually $999.99.

72
00:04:48,440 --> 00:04:50,560
This is not actually true.

73
00:04:50,560 --> 00:04:56,680
And so let's see how the model handles this user request.

74
00:04:56,680 --> 00:05:03,880
So we'll format into our messages array, and we'll get our response.

75
00:05:03,880 --> 00:05:16,280
And then we'll print it.

76
00:05:16,280 --> 00:05:20,400
And so what we're hoping for is that the model takes all of these different steps and realizes

77
00:05:20,400 --> 00:05:26,800
that the user has made an incorrect assumption, and then follows the final step to politely

78
00:05:26,800 --> 00:05:29,840
correct the user.

79
00:05:29,840 --> 00:05:35,480
And so within this one prompt, we've actually maintained a number of different complex states

80
00:05:35,480 --> 00:05:36,560
that the system could be in.

81
00:05:36,560 --> 00:05:41,440
So at any given point, there could be a different output from the previous step, and we would

82
00:05:41,440 --> 00:05:42,960
want to do something different.

83
00:05:42,960 --> 00:05:49,040
For example, if the user hadn't made any assumptions in step three, then in step four, we wouldn't

84
00:05:49,040 --> 00:05:50,280
actually have any output.

85
00:05:50,280 --> 00:05:53,360
So this is a pretty complicated instruction for the model.

86
00:05:53,360 --> 00:05:55,600
So let's see if it did it right.

87
00:05:55,600 --> 00:05:59,880
So step one, the user is asking a question about specific products.

88
00:05:59,880 --> 00:06:03,280
They're asking about the price difference between these two products.

89
00:06:03,280 --> 00:06:08,520
The user assumes that the BlueWave Chromebook is more expensive than the TechBook Pro, and

90
00:06:08,520 --> 00:06:10,960
this assumption is actually incorrect.

91
00:06:10,960 --> 00:06:14,280
It's reasoning through, taking longer to think about the problem.

92
00:06:14,280 --> 00:06:19,000
In the same way that a human would also take some time to reason about an answer to any

93
00:06:19,000 --> 00:06:23,720
given question, the model performs better if it also has time to think.

94
00:06:23,720 --> 00:06:28,600
And so the final response to the user is the BlueWave Chromebook is actually less expensive

95
00:06:28,600 --> 00:06:29,880
than the TechBook Pro.

96
00:06:29,880 --> 00:06:38,640
The TechBook Pro desktop costs $999.99, while the BlueWave Chromebook costs $249.99.

97
00:06:38,640 --> 00:06:42,840
And so let's see another example of a user message.

98
00:06:42,840 --> 00:06:49,600
And also at this point, feel free to pause the video and try your own messages.

99
00:06:49,600 --> 00:06:51,440
So let's format this user message.

100
00:06:51,440 --> 00:06:53,760
So the question is, do you sell TVs?

101
00:06:53,760 --> 00:06:58,360
And if you remember in our product list, we've only listed different computers.

102
00:06:58,360 --> 00:07:02,280
So let's see what the model says.

103
00:07:02,280 --> 00:07:07,600
So in this case, step one, the user is asking if the store sells TVs, but TVs are not listed

104
00:07:07,600 --> 00:07:08,760
in the available products.

105
00:07:08,760 --> 00:07:13,200
So as you can see, the model then skips to the response to user step because it realizes

106
00:07:13,200 --> 00:07:17,840
that the intermediary steps are not actually necessary.

107
00:07:17,840 --> 00:07:21,920
I will say that we did ask for the output in this specific format, so technically the

108
00:07:21,920 --> 00:07:24,600
model hasn't exactly followed our request.

109
00:07:24,600 --> 00:07:27,960
Again, more advanced models will be better at doing that.

110
00:07:27,960 --> 00:07:32,240
And so in this case, our response to the user is, I'm sorry, but we do not sell TVs at the

111
00:07:32,240 --> 00:07:33,240
store.

112
00:07:33,240 --> 00:07:37,840
And then it lists the available products.

113
00:07:37,840 --> 00:07:41,040
So again, feel free to try some of your own responses.

114
00:07:41,040 --> 00:07:45,080
And so now, we only really want this part of the response.

115
00:07:45,080 --> 00:07:47,920
We wouldn't want to show the earlier parts to the user.

116
00:07:47,920 --> 00:07:54,920
So what we can do is actually just cut the string at the last occurrence of this delimiter

117
00:07:54,920 --> 00:08:03,600
token or string of four hashtags, and then only print the final part of the model output.

118
00:08:03,600 --> 00:08:07,920
So let's write some code to get only the final part of this string.

119
00:08:07,920 --> 00:08:13,200
So we're going to use a try except block to gracefully handle errors in case the model

120
00:08:13,200 --> 00:08:19,120
has some kind of unpredictable output and doesn't actually use these characters.

121
00:08:19,120 --> 00:08:23,600
And so we're going to say our final response is the response.

122
00:08:23,600 --> 00:08:26,560
And then we're going to split the string at the delimiter string.

123
00:08:26,560 --> 00:08:31,400
And because we want the final occurrence, we just want to get the last item in the output

124
00:08:31,400 --> 00:08:32,920
list.

125
00:08:32,920 --> 00:08:36,240
And then we're going to strip any white space.

126
00:08:36,240 --> 00:08:40,600
Because as you can see, there might be white space after the characters.

127
00:08:40,600 --> 00:08:55,080
And we're going to catch any errors and have a fallback response, which is, sorry, I'm

128
00:08:55,080 --> 00:09:01,960
having trouble right now.

129
00:09:01,960 --> 00:09:08,440
Please try asking another question.

130
00:09:08,440 --> 00:09:22,160
And then let's print our final response.

131
00:09:22,160 --> 00:09:26,680
And so as you can see, we just cut the string to get this final output.

132
00:09:26,680 --> 00:09:32,400
And so this is what we would show to the user if we were building this into an application.

133
00:09:32,400 --> 00:09:37,640
And overall, I just want to call out this prompt might be slightly convoluted for this

134
00:09:37,640 --> 00:09:38,640
task.

135
00:09:38,640 --> 00:09:41,520
You might not actually need all of these intermediate steps.

136
00:09:41,520 --> 00:09:46,760
And so why don't you try and see if you can find an easier way to do the same task in

137
00:09:46,760 --> 00:09:50,040
your own prompt.

138
00:09:50,040 --> 00:09:55,200
And in general, finding the optimal tradeoff in prompt complexity requires some experimentation.

139
00:09:55,200 --> 00:09:59,240
So definitely good to try a number of different prompts before deciding to use one.

140
00:09:59,240 --> 00:10:04,840
And in the next video, we'll learn another strategy to handle complex tasks by splitting

141
00:10:04,840 --> 00:10:09,360
these complex tasks into a series of simpler subtasks rather than trying to do the whole

142
00:10:09,360 --> 00:10:36,440
task in one prompt.


