1
00:00:01,000 --> 00:00:05,000
In this video, we'll focus on checking outputs generated by the system.

2
00:00:05,000 --> 00:00:15,000
Checking outputs before showing them to users can be important for ensuring the quality, relevance and safety of the responses provided to them or used in automation flows.

3
00:00:15,000 --> 00:00:24,000
We'll learn how to use the moderation API, but this time for outputs, and how to use additional prompts to the model to evaluate output quality before displaying them.

4
00:00:24,000 --> 00:00:31,000
So let's dive into the examples.

5
00:00:31,000 --> 00:00:35,000
We've already discussed the moderation API in the context of evaluating inputs.

6
00:00:35,000 --> 00:00:39,000
Now let's revisit it in the context of checking outputs.

7
00:00:39,000 --> 00:00:45,000
Moderation API can also be used to filter and moderate outputs generated by the system itself.

8
00:00:45,000 --> 00:00:47,000
And so here's an example.

9
00:00:47,000 --> 00:00:54,000
So here's a generated response to the user.

10
00:00:54,000 --> 00:01:02,000
And we're going to use the moderation API in the same way that we saw the earlier video.

11
00:01:02,000 --> 00:01:06,000
So let's see if this output is flagged.

12
00:01:06,000 --> 00:01:16,000
And as you can see, this output is not flagged and has very low scores in all categories, which makes sense given the response.

13
00:01:16,000 --> 00:01:19,000
In general, it can also be important to check the outputs.

14
00:01:19,000 --> 00:01:28,000
For example, if you were creating a chatbot for sensitive audiences, you could use lower thresholds for flagging outputs.

15
00:01:28,000 --> 00:01:40,000
In general, if the moderation output indicates that the content is flagged, you can take appropriate actions such as responding with a fallback answer or generating a new response.

16
00:01:40,000 --> 00:01:48,000
Note that as we improve the models, they also are becoming less and less likely to return some kind of harmful output.

17
00:01:48,000 --> 00:01:56,000
Another approach for checking outputs is to ask the model itself if the generated was satisfactory and if it follows a certain rubric that you define.

18
00:01:56,000 --> 00:02:05,000
This can be done by providing the generated output as part of the input to the model and asking it to rate the quality of the output.

19
00:02:05,000 --> 00:02:07,000
You can do this in various different ways.

20
00:02:07,000 --> 00:02:10,000
So let's see an example.

21
00:02:10,000 --> 00:02:25,000
So our system message is you are an assistant that evaluates whether customer service agent responses sufficiently answer customer questions and also validates that all the facts the assistant cites from the product information are correct.

22
00:02:25,000 --> 00:02:33,000
The product information and user and customer service agent messages will be delivered by three backticks.

23
00:02:33,000 --> 00:02:37,000
Respond with a Y or N character with no punctuation.

24
00:02:37,000 --> 00:02:45,000
Y if the output sufficiently answers the question and the response correctly uses product information and no otherwise.

25
00:02:45,000 --> 00:02:47,000
I'll put a single letter only.

26
00:02:47,000 --> 00:02:52,000
And you could also use a chain of thought reasoning prompt for this.

27
00:02:52,000 --> 00:02:55,000
This might be a little bit difficult for the model to validate both in one step.

28
00:02:55,000 --> 00:02:57,000
So you could play around with this.

29
00:02:57,000 --> 00:02:59,000
You could also add some other kind of guidelines.

30
00:02:59,000 --> 00:03:05,000
You could ask give a rubric like a rubric for an exam or grading an essay.

31
00:03:05,000 --> 00:03:15,000
You could use that kind of format and say does this use a friendly tone in line with our brand guidelines and maybe outline some of your brand guidelines if that's something that's very important to you.

32
00:03:15,000 --> 00:03:17,000
So let's add our customer message.

33
00:03:17,000 --> 00:03:21,000
So this is the initial message used to generate this response.

34
00:03:21,000 --> 00:03:24,000
And then that's also paste in our product information.

35
00:03:24,000 --> 00:03:33,000
And so this is the product information we fetched in the previous step for all of the products mentioned in this message.

36
00:03:33,000 --> 00:03:37,000
And now we'll define our comparison.

37
00:03:37,000 --> 00:03:51,000
So the customer message is the customer message, the product information and then the agent response, which is the response to the customer that we have from this previous cell.

38
00:03:51,000 --> 00:03:59,000
So let's format this into a messages list and get the response from the model.

39
00:03:59,000 --> 00:04:06,000
So the model says, yes, the product information is correct and the question is answered sufficiently.

40
00:04:06,000 --> 00:04:15,000
Well, in general, for these kind of evaluation tasks, I also think it is better to use a more advanced model because they're just better at reasoning.

41
00:04:15,000 --> 00:04:20,000
So something like GPT-4.

42
00:04:20,000 --> 00:04:23,000
Let's try another example.

43
00:04:23,000 --> 00:04:27,000
So this response is life is like a box of chocolates.

44
00:04:27,000 --> 00:04:36,000
So let's add our message to do with the output checking.

45
00:04:36,000 --> 00:04:43,000
And the model has determined that this does not sufficiently answer the question or use the retrieved information.

46
00:04:43,000 --> 00:04:46,000
This question, does it use the retrieved information correctly?

47
00:04:46,000 --> 00:04:59,000
This is a good prompt to use if you want to make sure that the model isn't hallucinating, which is making up things that aren't true.

48
00:04:59,000 --> 00:05:11,000
And feel free to pause the video now and try some of your own customer messages, responses and adding product information to test how this works.

49
00:05:11,000 --> 00:05:21,000
So as you can see, the model can provide feedback on the quality of a generated output, and you can use this feedback to decide whether to present the output to the user or to generate a new response.

50
00:05:21,000 --> 00:05:28,000
You could even experiment with generating multiple model responses per user query and then having the model choose the best one to show the user.

51
00:05:28,000 --> 00:05:30,000
So there's lots of different things you could try.

52
00:05:30,000 --> 00:05:44,000
In general, checking outputs using the moderation API is good practice, but while asking the model to evaluate its own output might be useful for immediate feedback to ensure the quality of responses in a very small number of cases.

53
00:05:44,000 --> 00:05:50,000
I think it's probably unnecessary most of the time, especially if you're using a more advanced model like GPT-4.

54
00:05:50,000 --> 00:05:54,000
I haven't actually seen many people do something like this in production.

55
00:05:54,000 --> 00:06:01,000
You could also increase the latency and cost of your system because you'd have to wait for an additional call for the model, and that's also additional tokens.

56
00:06:01,000 --> 00:06:10,000
If it's really important for your app or product that your error rate is 0.0000001%, then maybe you should try this approach.

57
00:06:10,000 --> 00:06:13,000
But overall, I wouldn't really recommend that you do this in practice.

58
00:06:13,000 --> 00:06:22,000
In the next video, we're going to put together everything we've learned in the evaluate input section, process section and checking output section to build an end-to-end system.

59
00:06:22,000 --> 00:06:24,000
Thanks.


