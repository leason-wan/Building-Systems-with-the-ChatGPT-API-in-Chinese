1
00:00:00,000 --> 00:00:06,300
In the previous few videos,

2
00:00:06,360 --> 00:00:10,260
Isa showed how to build an application using an llm

3
00:00:10,320 --> 00:00:14,460
from evaluating the inputs to processing the inputs

4
00:00:14,520 --> 00:00:18,560
to then doing final output checking before you show the output to the user.

5
00:00:19,260 --> 00:00:22,520
After you've built such a system, how do you know how it's working?

6
00:00:22,600 --> 00:00:26,500
And maybe even as you deploy it and let users use it,

7
00:00:26,560 --> 00:00:29,020
how can you track how it's doing

8
00:00:29,020 --> 00:00:32,280
and find any shortcomings and continue to improve

9
00:00:32,340 --> 00:00:34,720
the quality of the answers of your system?

10
00:00:34,780 --> 00:00:37,520
In this video, I'd like to share with you some best practices

11
00:00:37,580 --> 00:00:41,040
for evaluating the outputs of an llm.

12
00:00:41,120 --> 00:00:42,920
And I want to share with you specifically

13
00:00:42,980 --> 00:00:46,140
what it feels like to build one of these systems.

14
00:00:46,220 --> 00:00:50,080
One key distinction between what you hear me talk about in this video

15
00:00:50,140 --> 00:00:53,480
and what you may have seen in more traditional machine learning,

16
00:00:53,540 --> 00:00:56,440
supervised learning applications is because you can build

17
00:00:56,440 --> 00:01:00,260
such an application so quickly, the methods for evaluating it,

18
00:01:00,340 --> 00:01:03,100
it tends not to start off with a test set.

19
00:01:03,160 --> 00:01:08,540
Instead, you often end up gradually building up a set of test examples.

20
00:01:08,600 --> 00:01:10,640
Let me share with you what I mean by that.

21
00:01:10,700 --> 00:01:13,200
You will remember this diagram from the second video

22
00:01:13,260 --> 00:01:17,000
about how prompt-based development speeds up the core parts

23
00:01:17,060 --> 00:01:22,140
of model development from maybe months to just minutes or hours

24
00:01:22,200 --> 00:01:24,300
or at most a very small number of days.

25
00:01:24,300 --> 00:01:27,100
In the traditional supervised learning approach,

26
00:01:27,160 --> 00:01:31,260
if you needed to collect, say, 10,000 labeled examples anyway,

27
00:01:31,340 --> 00:01:35,840
then the incremental cost of collecting another 1000 test examples

28
00:01:35,900 --> 00:01:36,940
isn't that bad.

29
00:01:37,000 --> 00:01:40,200
So in the traditional supervised learning setting,

30
00:01:40,260 --> 00:01:42,900
it was not unusual to collect a training set,

31
00:01:42,960 --> 00:01:46,300
collect a development set or holdout cross-validation set

32
00:01:46,360 --> 00:01:48,740
in the test set, and then tap those at hand

33
00:01:48,800 --> 00:01:51,260
throughout this development process.

34
00:01:51,260 --> 00:01:54,620
But if you're able to specify a prompt in just minutes

35
00:01:54,680 --> 00:01:56,780
and get something working in hours,

36
00:01:56,860 --> 00:01:58,660
then it would seem like a huge pain

37
00:01:58,720 --> 00:02:01,360
if you had to pause for a long time

38
00:02:01,420 --> 00:02:03,680
to collect a thousand test examples

39
00:02:03,760 --> 00:02:07,480
because you can now get this working with zero training examples.

40
00:02:08,060 --> 00:02:11,360
So when building an application using an LLM,

41
00:02:11,420 --> 00:02:13,420
this is what it often feels like.

42
00:02:13,480 --> 00:02:17,420
First, you would tune the prompts on just a small handful of examples,

43
00:02:17,480 --> 00:02:20,320
maybe one to three to five examples.

44
00:02:20,320 --> 00:02:22,800
And try to get a prompt that works on them.

45
00:02:22,860 --> 00:02:26,800
And then as you have the system undergo additional testing,

46
00:02:26,860 --> 00:02:30,400
you occasionally run into a few examples that are tricky.

47
00:02:30,460 --> 00:02:33,760
The prompt doesn't work on them or the algorithm doesn't work on them.

48
00:02:33,820 --> 00:02:36,800
And in that case, you can take these additional one or two

49
00:02:36,860 --> 00:02:41,000
or three or five examples and add them to the set that you're testing on

50
00:02:41,060 --> 00:02:44,260
to just add additional tricky examples opportunistically.

51
00:02:44,960 --> 00:02:48,320
Eventually, you have enough of these examples you've added

52
00:02:48,320 --> 00:02:51,840
to your slowly growing development set

53
00:02:51,920 --> 00:02:54,120
that it becomes a bit inconvenient

54
00:02:54,180 --> 00:02:56,620
to manually run every example through the prompt

55
00:02:56,680 --> 00:02:58,120
every time you change the prompt.

56
00:02:58,180 --> 00:03:01,280
And then you start to develop metrics to measure performance

57
00:03:01,340 --> 00:03:04,320
on this small set of examples, such as maybe average accuracy.

58
00:03:05,380 --> 00:03:09,440
And one interesting aspect of this process

59
00:03:09,520 --> 00:03:12,480
is if you decide at any moment in time

60
00:03:12,540 --> 00:03:14,380
your system is working well enough,

61
00:03:14,440 --> 00:03:16,520
you can stop right there and not use it.

62
00:03:16,520 --> 00:03:19,860
You can stop right there and not go on to the next bullet.

63
00:03:20,460 --> 00:03:22,620
And in fact, there are many deploy applications

64
00:03:22,680 --> 00:03:25,980
that stops at maybe the first or the second bullet

65
00:03:26,060 --> 00:03:29,060
and are running just fine.

66
00:03:30,320 --> 00:03:35,180
Now, if your hand-built development set

67
00:03:35,260 --> 00:03:37,120
that you're evaluating the model on

68
00:03:37,180 --> 00:03:39,520
isn't giving you sufficient confidence yet

69
00:03:39,580 --> 00:03:41,160
in the performance of your system,

70
00:03:41,220 --> 00:03:43,720
then that's when you may go to the next step

71
00:03:43,720 --> 00:03:47,560
of collecting a randomly sampled set of examples

72
00:03:47,620 --> 00:03:49,320
to tune the model to.

73
00:03:49,400 --> 00:03:52,360
And this would continue to be a development set

74
00:03:52,420 --> 00:03:53,920
or a holdout cross-validation set,

75
00:03:54,000 --> 00:03:58,800
because it'd be quite common to continue to tune your prompt to this.

76
00:03:59,760 --> 00:04:03,920
And only if you need even higher fidelity estimate

77
00:04:04,000 --> 00:04:05,320
of the performance of your system,

78
00:04:05,400 --> 00:04:08,600
then might you collect and use a holdout test sets

79
00:04:08,660 --> 00:04:11,360
that you don't even look at yourself

80
00:04:11,360 --> 00:04:14,200
when you're tuning the model.

81
00:04:14,260 --> 00:04:17,660
And so, step four tends to be more important

82
00:04:17,740 --> 00:04:22,700
if, say, your system is getting the right answer 91% of the time,

83
00:04:22,760 --> 00:04:26,760
and you want to tune it to get it to give the right answer 92%

84
00:04:26,840 --> 00:04:28,600
or 93% of the time,

85
00:04:28,660 --> 00:04:30,960
then you do need a larger set of examples

86
00:04:31,040 --> 00:04:36,500
to measure those differences between 91% and 93% performance.

87
00:04:36,560 --> 00:04:40,000
And then only if you really need an unbiased,

88
00:04:40,000 --> 00:04:42,140
fair estimate of how was the system doing,

89
00:04:42,200 --> 00:04:45,080
then do you need to go beyond the development set

90
00:04:45,140 --> 00:04:47,340
to also collect a holdout test set.

91
00:04:47,400 --> 00:04:49,100
One important caveat,

92
00:04:49,180 --> 00:04:51,780
I've seen a lot of applications of large language models

93
00:04:51,840 --> 00:04:56,280
where there isn't meaningful risk of harm

94
00:04:56,340 --> 00:04:58,780
if it gives not quite the right answer.

95
00:04:58,840 --> 00:05:01,540
But obviously, for any high-stakes applications,

96
00:05:01,600 --> 00:05:05,940
if there's a risk of bias or an inappropriate output

97
00:05:06,000 --> 00:05:08,300
causing harm to someone,

98
00:05:08,300 --> 00:05:10,720
then the responsibility to collect a test set

99
00:05:10,800 --> 00:05:13,420
to rigorously evaluate the performance of your system

100
00:05:13,500 --> 00:05:16,420
to make sure it's doing the right thing before you use it,

101
00:05:16,500 --> 00:05:18,660
that becomes much more important.

102
00:05:18,720 --> 00:05:20,520
But if, for example,

103
00:05:20,600 --> 00:05:23,160
if you are using it to summarize articles

104
00:05:23,220 --> 00:05:25,860
just for yourself to read and no one else,

105
00:05:25,920 --> 00:05:28,600
then maybe the risk of harm is more modest,

106
00:05:28,660 --> 00:05:30,720
and you can stop early in this process

107
00:05:30,800 --> 00:05:33,760
without going to the expense of bullets four and five

108
00:05:33,820 --> 00:05:37,920
of collecting larger data sets on which to evaluate your algorithm.

109
00:05:37,920 --> 00:05:40,880
So in this example,

110
00:05:40,940 --> 00:05:43,680
let me start with the usual helper functions.

111
00:05:48,240 --> 00:05:52,880
Use a utils function to get a list of products and categories.

112
00:05:52,940 --> 00:05:56,880
So in the computers and laptop category,

113
00:05:56,940 --> 00:05:58,880
there's a list of computers and laptops.

114
00:05:58,940 --> 00:06:00,980
In the smartphones and accessories category,

115
00:06:01,040 --> 00:06:03,080
here's a list of smartphones and accessories,

116
00:06:03,080 --> 00:06:08,080
and so on for other categories.

117
00:06:11,780 --> 00:06:21,780
Now, let's say the task of an address is given a user input,

118
00:06:21,860 --> 00:06:25,980
such as what TV can I buy if I'm on a budget

119
00:06:26,060 --> 00:06:30,060
to retrieve the relevant categories and products

120
00:06:30,060 --> 00:06:34,720
so that we have the right info to answer the user's query.

121
00:06:34,800 --> 00:06:35,800
So here's a prompt.

122
00:06:35,860 --> 00:06:36,920
Feel free to pause the video

123
00:06:37,000 --> 00:06:39,200
and read through this in detail if you wish.

124
00:06:39,260 --> 00:06:42,120
But the prompt specifies a set of instructions,

125
00:06:42,200 --> 00:06:44,700
and it actually gives the language model

126
00:06:44,760 --> 00:06:47,000
one example of a good output.

127
00:06:47,060 --> 00:06:48,760
This is sometimes called a few-shot

128
00:06:48,820 --> 00:06:50,200
or technically one-shot prompting

129
00:06:50,260 --> 00:06:52,560
because we're actually using a user message

130
00:06:52,620 --> 00:06:56,500
and a system message to give it one example of a good output.

131
00:06:56,560 --> 00:06:59,020
If someone says, I want the most expensive computer,

132
00:06:59,020 --> 00:07:01,180
let's just return all the computers

133
00:07:01,240 --> 00:07:03,380
because we don't have pricing information.

134
00:07:03,440 --> 00:07:08,120
Now, let's use this prompt on the customer message,

135
00:07:08,180 --> 00:07:12,180
which TV can I buy if I'm on a budget?

136
00:07:15,040 --> 00:07:19,040
And so we're passing in to this both the prompt,

137
00:07:19,120 --> 00:07:22,040
customer message zero, as well as the products and category.

138
00:07:22,120 --> 00:07:24,540
This is the information that we have retrieved up top

139
00:07:24,620 --> 00:07:26,380
using the utils function.

140
00:07:26,380 --> 00:07:30,320
And here it lists out the relevant information to this query,

141
00:07:30,380 --> 00:07:32,580
which is under the category televisions

142
00:07:32,660 --> 00:07:33,720
and whole theater systems.

143
00:07:33,780 --> 00:07:36,480
This is a list of TVs and whole theater systems

144
00:07:36,560 --> 00:07:37,760
that seem relevant.

145
00:07:37,820 --> 00:07:39,520
To see how well the prompt is doing,

146
00:07:39,580 --> 00:07:43,280
you may evaluate it on a second prompt.

147
00:07:43,360 --> 00:07:46,960
Customer says I need a charger for my smartphone.

148
00:07:47,020 --> 00:07:52,060
It looks like it's correctly retrieving this data.

149
00:07:52,120 --> 00:07:53,620
Category smartphones and accessories,

150
00:07:53,680 --> 00:07:55,760
and it lists the relevant products

151
00:07:55,760 --> 00:07:57,760
and here's another one.

152
00:08:00,320 --> 00:08:02,560
So what computers do you have?

153
00:08:02,620 --> 00:08:06,120
And hopefully you'll retrieve a list of the computers.

154
00:08:06,200 --> 00:08:08,400
So here I have three prompts.

155
00:08:08,460 --> 00:08:12,560
And if you are developing this prompt for the first time,

156
00:08:12,620 --> 00:08:16,360
it would be quite reasonable to have one or two

157
00:08:16,420 --> 00:08:18,120
or three examples like this,

158
00:08:18,200 --> 00:08:19,860
and to keep on tuning the prompt

159
00:08:19,920 --> 00:08:22,620
until it gives appropriate outputs,

160
00:08:22,700 --> 00:08:25,200
until the prompt is retrieving the relevant products

161
00:08:25,200 --> 00:08:27,940
and categories to the customer requests

162
00:08:28,000 --> 00:08:29,900
for all of your prompts,

163
00:08:29,960 --> 00:08:31,600
all three of them in this example.

164
00:08:34,360 --> 00:08:37,500
And if the prompt had been missing some products

165
00:08:37,560 --> 00:08:39,760
or something, then what we would do is probably go back

166
00:08:39,840 --> 00:08:41,960
to edit the prompt a few times until it gets it right

167
00:08:42,040 --> 00:08:43,640
on all three of these prompts.

168
00:08:46,000 --> 00:08:49,600
After you've gotten the system to this point,

169
00:08:49,660 --> 00:08:52,900
you might then start running the system in testing,

170
00:08:52,900 --> 00:08:55,640
maybe send it to internal test users

171
00:08:55,700 --> 00:08:57,240
or try using it yourself

172
00:08:57,300 --> 00:09:00,140
and just run it for a while to see what happens.

173
00:09:00,200 --> 00:09:03,900
And sometimes you will run across a prompt

174
00:09:03,980 --> 00:09:05,540
that it fails on.

175
00:09:05,600 --> 00:09:07,240
So here's an example of a prompt.

176
00:09:07,300 --> 00:09:09,540
Tell me about the SmartX profile and the Philips Now camera,

177
00:09:09,600 --> 00:09:11,580
also what TVs you have.

178
00:09:11,640 --> 00:09:12,980
So when I run it on this prompt,

179
00:09:13,040 --> 00:09:16,380
it looks like it's outputting the right data,

180
00:09:16,440 --> 00:09:18,640
but it also outputs a bunch of text here,

181
00:09:18,700 --> 00:09:20,440
this extra junk.

182
00:09:20,440 --> 00:09:26,520
It makes it harder to parse this into a Python list of dictionaries.

183
00:09:26,580 --> 00:09:29,720
So we don't like that it's outputting this extra junk.

184
00:09:29,780 --> 00:09:34,580
So when you run across one example that the system fails on,

185
00:09:34,640 --> 00:09:36,980
then common practice is to just note down

186
00:09:37,040 --> 00:09:39,020
that this is a somewhat tricky example.

187
00:09:39,080 --> 00:09:41,280
So let's add this to our set of examples

188
00:09:41,340 --> 00:09:44,580
that we're going to test the system on systematically.

189
00:09:44,640 --> 00:09:47,980
And if you keep on running the system for a while longer,

190
00:09:48,040 --> 00:09:49,520
maybe it works on those examples.

191
00:09:49,520 --> 00:09:51,180
We did tune the prompt to three examples,

192
00:09:51,260 --> 00:09:52,980
so maybe it will work on many examples.

193
00:09:53,060 --> 00:09:56,760
But just by chance, you might run across another example

194
00:09:56,820 --> 00:09:58,660
where it generates an error.

195
00:09:58,720 --> 00:10:02,920
So this customer message for also causes the system

196
00:10:02,980 --> 00:10:07,120
to output a bunch of junk text at the end that we don't want.

197
00:10:10,320 --> 00:10:11,980
Trying to be helpful to get all this extra text,

198
00:10:12,060 --> 00:10:13,360
but we actually don't want this.

199
00:10:13,420 --> 00:10:15,720
And so at this point, you may have run this prompt

200
00:10:15,720 --> 00:10:19,500
maybe on hundreds of examples, maybe your test users,

201
00:10:19,560 --> 00:10:21,320
but you would just take the examples,

202
00:10:21,400 --> 00:10:23,560
the tricky ones it's doing poorly on,

203
00:10:23,620 --> 00:10:28,360
and now have this set of five examples indexed from zero to four,

204
00:10:28,420 --> 00:10:30,560
have this set of five examples that you use

205
00:10:30,620 --> 00:10:32,460
to further fine tune the prompts.

206
00:10:34,020 --> 00:10:38,220
And in both of these examples,

207
00:10:38,300 --> 00:10:41,800
the LM had output a bunch of extra junk text

208
00:10:41,860 --> 00:10:44,020
at the end that we don't want.

209
00:10:44,020 --> 00:10:46,640
And after a little bit of trial and error,

210
00:10:46,720 --> 00:10:49,880
you might decide to modify the prompts as follows.

211
00:10:51,020 --> 00:10:52,220
So here's a new prompt.

212
00:10:52,280 --> 00:10:54,180
This is called prompt V2.

213
00:10:54,240 --> 00:10:57,380
But what we did here was we added to the prompt,

214
00:10:57,440 --> 00:11:00,180
do not output any additional text that's not in JSON format,

215
00:11:00,240 --> 00:11:03,080
just to emphasize, please don't output this JSON stuff,

216
00:11:03,140 --> 00:11:06,840
and added a second example using the user

217
00:11:06,920 --> 00:11:09,180
and assistant message for few-shot prompting,

218
00:11:09,240 --> 00:11:12,080
where the user asked the cheapest computer.

219
00:11:12,080 --> 00:11:14,820
And in both of the few-shot examples,

220
00:11:14,880 --> 00:11:17,760
we're demonstrating to the system a response

221
00:11:17,820 --> 00:11:20,860
where it gives only JSON output.

222
00:11:20,920 --> 00:11:23,220
So here's the extra thing that we just added to the prompt,

223
00:11:23,280 --> 00:11:25,660
do not put any additional text that's not in JSON format.

224
00:11:25,720 --> 00:11:29,060
And we use few-shot user one, few-shot assistant one,

225
00:11:29,120 --> 00:11:31,320
and few-shot user two, few-shot assistant two,

226
00:11:31,380 --> 00:11:35,420
to give it two of these few-shot prompts.

227
00:11:35,480 --> 00:11:38,960
So let me hit shift enter to find that prompt.

228
00:11:39,020 --> 00:11:41,760
And you were to go back and manually rerun this prompt

229
00:11:41,760 --> 00:11:44,000
on all five of the examples of user inputs,

230
00:11:44,060 --> 00:11:47,360
including this one that previously had given a broken output,

231
00:11:47,420 --> 00:11:50,100
you find that it now gives a correct output.

232
00:11:51,100 --> 00:11:53,860
And if you were to go back and rerun this new prompt,

233
00:11:53,920 --> 00:11:59,120
this is prompt version V2, on that customer message example

234
00:11:59,200 --> 00:12:01,120
that had resulted in the broken output

235
00:12:01,200 --> 00:12:03,400
with extra junk after the JSON output,

236
00:12:03,960 --> 00:12:07,960
then this will generate a better output.

237
00:12:08,700 --> 00:12:09,860
And I'm not going to do it here,

238
00:12:09,860 --> 00:12:12,040
but I encourage you to pause the video

239
00:12:12,100 --> 00:12:14,640
and rerun it yourself on customer message four

240
00:12:14,700 --> 00:12:16,600
as well on this prompt V2,

241
00:12:16,660 --> 00:12:20,000
see if it also generates the correct output.

242
00:12:20,060 --> 00:12:21,660
And hopefully it will, I think it should.

243
00:12:24,340 --> 00:12:26,640
And of course, when you modify the prompts,

244
00:12:26,700 --> 00:12:31,140
it's also useful to do a bit of regression testing

245
00:12:31,200 --> 00:12:34,960
to make sure that when fixing the incorrect outputs

246
00:12:35,040 --> 00:12:36,500
on prompts three and four,

247
00:12:36,500 --> 00:12:39,940
it didn't break the outputs on prompt zero either.

248
00:12:41,280 --> 00:12:46,080
Now, you can kind of tell that if I had to copy paste five prompts,

249
00:12:46,140 --> 00:12:49,040
customer such as zero, one, two, three, and four,

250
00:12:49,100 --> 00:12:50,740
into my Jupyter Notebook and run them

251
00:12:50,800 --> 00:12:53,400
and then manually look at them to see if they are putting

252
00:12:53,480 --> 00:12:56,380
the right categories and products, you can kind of do it.

253
00:12:56,440 --> 00:12:58,540
I can look at this and go, yep, category TV

254
00:12:58,600 --> 00:13:00,040
and home theater systems products.

255
00:13:00,100 --> 00:13:01,840
Yep, looks like you got all of them.

256
00:13:01,900 --> 00:13:04,380
But it's actually a little bit painful to do this manually,

257
00:13:04,380 --> 00:13:07,420
to manually inspect or to look at this output,

258
00:13:07,480 --> 00:13:10,880
to make sure with your eyes that this is exactly the right output.

259
00:13:11,880 --> 00:13:15,920
So when the development set that you're tuning to

260
00:13:15,980 --> 00:13:18,820
becomes more than just a small handful of examples,

261
00:13:19,580 --> 00:13:25,520
it then becomes useful to start to automate the testing process.

262
00:13:26,920 --> 00:13:31,780
So here is a set of 10 examples

263
00:13:31,780 --> 00:13:35,460
where I'm specifying 10 customer messages.

264
00:13:35,520 --> 00:13:38,920
So here's the customer message, what TV can I buy from a budget,

265
00:13:38,980 --> 00:13:41,520
as well as what's the ideal answer.

266
00:13:41,580 --> 00:13:45,320
Think of this as the right answer in the test set,

267
00:13:45,380 --> 00:13:46,980
or really, I should say development set,

268
00:13:47,060 --> 00:13:48,920
because we're actually tuning to this.

269
00:13:48,980 --> 00:13:54,480
And so we've collected here 10 examples indexed from zero through nine,

270
00:13:55,580 --> 00:13:58,620
where the last one is if the user says,

271
00:13:58,620 --> 00:14:02,460
I would like hot tub time machine, we have no relevant products to that,

272
00:14:02,520 --> 00:14:05,360
really sorry. So the ideal answer is the empty set.

273
00:14:06,720 --> 00:14:13,020
And now, if you want to evaluate automatically,

274
00:14:13,400 --> 00:14:16,900
what a prompt is doing on any of these 10 examples,

275
00:14:17,500 --> 00:14:21,360
here is a function to do so. It's kind of a long function.

276
00:14:21,420 --> 00:14:23,800
Feel free to pause the video and read through it if you wish.

277
00:14:23,860 --> 00:14:26,800
But let me just demonstrate what it is actually doing.

278
00:14:26,800 --> 00:14:30,960
So let me print out the customer message for customer message zero.

279
00:14:31,940 --> 00:14:33,440
Right, so customer messages,

280
00:14:33,500 --> 00:14:35,600
which TV can I buy if I'm on a budget?

281
00:14:36,540 --> 00:14:40,860
And let's also print out the ideal answer.

282
00:14:40,940 --> 00:14:43,060
So the ideal answer is here are all the TVs

283
00:14:43,140 --> 00:14:45,760
that we want the prompt to retrieve.

284
00:14:48,000 --> 00:14:50,360
And let me now call the prompt.

285
00:14:50,440 --> 00:14:53,600
This is prompt V2 on this customer message

286
00:14:53,660 --> 00:14:55,760
with that user products and category information.

287
00:14:55,760 --> 00:14:56,880
Let's print it out.

288
00:14:56,960 --> 00:15:03,620
And then we'll call the eval responsive ideal function

289
00:15:04,320 --> 00:15:07,720
to see how well the response matches the ideal answer.

290
00:15:08,280 --> 00:15:11,920
And in this case, it did output the category that we wanted

291
00:15:11,980 --> 00:15:15,220
and it did output the entire list of products.

292
00:15:15,280 --> 00:15:18,680
And so this gives you the score of 1.0.

293
00:15:20,560 --> 00:15:22,420
Just to show you one more example,

294
00:15:22,420 --> 00:15:26,920
it turns out that I know it gets it wrong on example seven.

295
00:15:27,400 --> 00:15:30,600
So if I change this from zero to seven and run it,

296
00:15:34,560 --> 00:15:35,920
this is what it gets.

297
00:15:36,000 --> 00:15:41,100
Oh, let me update this to seven as well.

298
00:15:41,160 --> 00:15:45,620
So under this customer message, this is the ideal answer

299
00:15:45,700 --> 00:15:49,420
where it should output under gaming consoles and accessories.

300
00:15:49,500 --> 00:15:51,420
So this is gaming consoles and accessories.

301
00:15:51,420 --> 00:15:54,620
But whereas the response here has three outputs,

302
00:15:55,420 --> 00:16:00,480
it actually should have had one, two, three, four, five outputs.

303
00:16:00,540 --> 00:16:02,740
And so it's missing some of the products.

304
00:16:03,340 --> 00:16:07,740
So what I would do if I'm tuning the prompt now is I would then

305
00:16:09,180 --> 00:16:15,020
use a for loop to loop over all 10 of the development set examples

306
00:16:15,420 --> 00:16:18,140
where we repeatedly pull out the customer message,

307
00:16:18,140 --> 00:16:21,500
get the ideal answer, the right answer,

308
00:16:21,560 --> 00:16:24,700
call the arm to get a response, evaluate it,

309
00:16:24,760 --> 00:16:26,800
and then, you know, accumulate it in average.

310
00:16:26,860 --> 00:16:28,100
And let me just run this.

311
00:16:28,160 --> 00:16:30,900
All right.

312
00:16:30,960 --> 00:16:32,600
So this will take a while to run,

313
00:16:32,660 --> 00:16:34,860
but when it's done running, this is the result.

314
00:16:34,940 --> 00:16:37,740
We're running through the 10 examples.

315
00:16:37,800 --> 00:16:40,200
It looks like example seven was wrong.

316
00:16:40,260 --> 00:16:43,660
And so the fraction correct of 10 was 90% correct.

317
00:16:43,660 --> 00:16:46,920
And so if you were to tune the prompts,

318
00:16:46,980 --> 00:16:51,220
you can rerun this to see if the percent correct goes up or down.

319
00:16:51,780 --> 00:16:54,520
What you just saw in this notebook

320
00:16:54,580 --> 00:16:58,720
is going through steps one, two, and three of this bulletin list.

321
00:16:58,780 --> 00:17:03,120
And this already gives a pretty good development set of 10 examples

322
00:17:03,180 --> 00:17:06,420
with which to tune and validate the prompts is working.

323
00:17:07,120 --> 00:17:09,720
If you needed an additional level of rigor,

324
00:17:09,780 --> 00:17:11,820
then you now have the software needed

325
00:17:11,820 --> 00:17:15,800
to collect a randomly sampled set of maybe 100 examples

326
00:17:15,860 --> 00:17:17,800
with their ideal outputs,

327
00:17:17,860 --> 00:17:20,800
and maybe even go beyond that to the rigor of a holdout test set

328
00:17:20,860 --> 00:17:23,600
that you don't even look at while you're tuning the prompt.

329
00:17:23,660 --> 00:17:27,400
But for a lot of applications, stopping at bullet three,

330
00:17:27,460 --> 00:17:29,400
but there are also certainly applications

331
00:17:29,460 --> 00:17:33,100
where you could do what you just saw me do in this Jupyter notebook,

332
00:17:33,160 --> 00:17:36,560
and they get a pretty performance system quite quickly.

333
00:17:37,420 --> 00:17:39,600
With, again, the important caveat that,

334
00:17:39,600 --> 00:17:43,400
if you're working on a safety critical application

335
00:17:43,460 --> 00:17:47,800
or an application where there's non-trivial risk of harm,

336
00:17:47,860 --> 00:17:50,600
then of course, it would be the responsible thing to do

337
00:17:50,660 --> 00:17:52,300
to actually get a much larger test set

338
00:17:52,360 --> 00:17:55,540
to really verify the performance before you use it anywhere.

339
00:17:55,600 --> 00:17:56,800
And so that's it.

340
00:17:56,860 --> 00:18:00,300
I find that the workflow of building applications using prompts

341
00:18:00,360 --> 00:18:04,000
is very different than a workflow of building applications

342
00:18:04,060 --> 00:18:05,800
using supervised learning.

343
00:18:05,860 --> 00:18:08,400
And so I think that's a good thing to keep in mind

344
00:18:08,400 --> 00:18:10,340
when you're building supervised learning.

345
00:18:10,400 --> 00:18:13,380
And the pace of iteration feels much faster.

346
00:18:13,440 --> 00:18:15,700
And if you have not yet done it before,

347
00:18:15,780 --> 00:18:19,900
you might be surprised at how well an evaluation method

348
00:18:19,980 --> 00:18:22,980
built on just a few hand curated tricky examples.

349
00:18:23,040 --> 00:18:24,700
You think with 10 examples,

350
00:18:24,780 --> 00:18:28,180
and this is not statistically valid for almost anything.

351
00:18:28,240 --> 00:18:30,840
But you might be surprised when you actually use this procedure,

352
00:18:30,900 --> 00:18:33,580
how effective adding a handful,

353
00:18:33,640 --> 00:18:36,880
just a handful of tricky examples into development sets

354
00:18:36,880 --> 00:18:38,620
in terms of helping you and your team

355
00:18:38,680 --> 00:18:41,640
get to an effective set of prompts and effective system.

356
00:18:43,440 --> 00:18:49,120
In this video, the outputs could be evaluated quantitatively,

357
00:18:49,180 --> 00:18:51,680
as in there was a desired output,

358
00:18:51,740 --> 00:18:55,340
and you could tell if it gave this desired output or not.

359
00:18:55,420 --> 00:18:58,840
So the next video, let's take a look at how you can evaluate

360
00:18:58,920 --> 00:19:02,540
our outputs in that setting where what is the right answer

361
00:19:02,540 --> 00:19:07,540
is a bit more ambiguous.


